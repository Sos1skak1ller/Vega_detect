{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0b7e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kushnikov/Desktop/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0004a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060130d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label\n",
    "\n",
    "def dark_ratio(img: np.ndarray, dark_thresh: int = 40) -> float:\n",
    "    return float((img < dark_thresh).sum()) / img.size\n",
    "\n",
    "def image_dark_percent(image_path: str, dark_thresh: int = 40) -> float:\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    return dark_ratio(img, dark_thresh)\n",
    "\n",
    "def analyse_folder_darkness(folder: str, dark_thresh: int = 40, csv_path: str | None = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        pct = image_dark_percent(os.path.join(folder, fname), dark_thresh) * 100\n",
    "        rows.append({\"image\": fname, \"dark_%\": pct})\n",
    "    df = pd.DataFrame(rows).sort_values(\"dark_%\", ascending=False)\n",
    "    if csv_path:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    img = cv2.convertScaleAbs(img, alpha=1.5, beta=0)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "def tune_params(tile: np.ndarray, low: float = 0.40, mid: float = 0.20, area_min_urban: float = 0.001) -> Tuple[float, float]:\n",
    "    dr = dark_ratio(tile)\n",
    "    if dr > low:\n",
    "        return area_min_urban / 5, 1.5\n",
    "    if dr > mid:\n",
    "        return area_min_urban / 2, 1.8\n",
    "    return area_min_urban, 2.2\n",
    "\n",
    "def merge_boxes(boxes: List[Tuple[int, int, int, int]], merge_distance: int = 10) -> List[Tuple[int, int, int, int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    boxes = [list(b) for b in boxes]\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        result = []\n",
    "        used = [False] * len(boxes)\n",
    "        for i in range(len(boxes)):\n",
    "            if used[i]: continue\n",
    "            x1, y1, x2, y2 = boxes[i]\n",
    "            for j in range(i + 1, len(boxes)):\n",
    "                if used[j]: continue\n",
    "                x1_, y1_, x2_, y2_ = boxes[j]\n",
    "                if x1_ <= x2 + merge_distance and x2_ >= x1 - merge_distance and \\\n",
    "                   y1_ <= y2 + merge_distance and y2_ >= y1 - merge_distance:\n",
    "                    x1 = min(x1, x1_); y1 = min(y1, y1_); x2 = max(x2, x2_); y2 = max(y2, y2_)\n",
    "                    used[j] = True\n",
    "                    merged = True\n",
    "            result.append((x1, y1, x2, y2))\n",
    "            used[i] = True\n",
    "        boxes = result\n",
    "    return boxes\n",
    "\n",
    "def detect_objects(tile: np.ndarray, area_thresh: float, intensity_ratio: float) -> List[Tuple[int, int, int, int]]:\n",
    "    img = preprocess(tile)\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, -5)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k)\n",
    "\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    objs = []\n",
    "    h, w = tile.shape\n",
    "    bg_mean = np.median(tile)\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "        area = bw * bh\n",
    "\n",
    "        if area < area_thresh * h * w:\n",
    "            continue\n",
    "\n",
    "        roi = tile[y:y+bh, x:x+bw]\n",
    "        if roi.mean() < bg_mean * intensity_ratio:\n",
    "            continue\n",
    "\n",
    "        aspect = max(bw / bh, bh / bw)\n",
    "        if aspect > 8:\n",
    "            continue\n",
    "\n",
    "        compactness = area / (4 * np.pi * ((bw / 2 + bh / 2)**2))\n",
    "        if compactness < 0.02:\n",
    "            continue\n",
    "\n",
    "        objs.append((x, y, x + bw, y + bh))\n",
    "\n",
    "    return merge_boxes(objs)\n",
    "\n",
    "\n",
    "def segment_water_land(img: np.ndarray, water_thresh_factor: float = 0.6) -> np.ndarray:\n",
    "    blurred = cv2.medianBlur(img, 5)\n",
    "    median_intensity = np.median(blurred)\n",
    "    adaptive_thresh = int(median_intensity * water_thresh_factor)\n",
    "    _, mask = cv2.threshold(blurred, adaptive_thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "def draw_water_contours(image: np.ndarray, water_mask: np.ndarray) -> np.ndarray:\n",
    "    contours, _ = cv2.findContours(water_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    output = image.copy()\n",
    "    cv2.drawContours(output, contours, -1, (255, 0, 0), 2)\n",
    "    return output\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tw, th = max_tile_size\n",
    "    tiles = []\n",
    "    for y in range(0, h, th):\n",
    "        for x in range(0, w, tw):\n",
    "            tiles.append((image[y:y + th, x:x + tw], x, y))\n",
    "    return tiles\n",
    "\n",
    "def process_image(image_path: str, max_tile_size=(2000, 2000), low: float = 0.40, mid: float = 0.20, area_min: float = 0.001):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    boxes = []\n",
    "    for tile, xo, yo in split_image(img, max_tile_size):\n",
    "        area_t, ratio_t = tune_params(tile, low, mid, area_min)\n",
    "        for x1, y1, x2, y2 in detect_objects(tile, area_t, ratio_t):\n",
    "            boxes.append((x1 + xo, y1 + yo, x2 + xo, y2 + yo))\n",
    "    water_mask = segment_water_land(img)\n",
    "    return merge_boxes(boxes), water_mask\n",
    "\n",
    "def draw_objects(image_path: str, objects, water_mask: np.ndarray, output_path: str):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "    img = draw_water_contours(img, water_mask)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "def process_folder(input_folder: str, output_folder: str, max_tile_size=(2000, 2000),\n",
    "                   low: float = 0.40, mid: float = 0.20, area_min: float = 0.001):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "        pct_dark = image_dark_percent(inp) * 100\n",
    "        scene = \"water-heavy\" if pct_dark > low * 100 else \"mixed\" if pct_dark > mid * 100 else \"urban\"\n",
    "        print(f\"{fname}: dark {pct_dark:.1f}% → {scene} params\")\n",
    "        boxes, water_mask = process_image(inp, max_tile_size, low, mid, area_min)\n",
    "        out_img = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        draw_objects(inp, boxes, water_mask, out_img)\n",
    "        box_df = pd.DataFrame(boxes, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "        box_df.to_csv(os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_boxes.csv\"), index=False)\n",
    "        summary.append({\"image\": fname, \"dark_%\": pct_dark, \"objects\": len(boxes),\n",
    "                        \"scene\": scene, \"output\": out_img})\n",
    "    if summary:\n",
    "        pd.DataFrame(summary).to_csv(os.path.join(output_folder, \"summary.csv\"), index=False)\n",
    "        print(\"CSV summary saved → summary.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564a878",
   "metadata": {},
   "source": [
    "Намного лучше, но без выделения воды и с некоторыми косяками связанными с выделением точек интереса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474442c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dark_ratio(img: np.ndarray, dark_thresh: int = 40) -> float:\n",
    "    return float((img < dark_thresh).sum()) / img.size\n",
    "\n",
    "def image_dark_percent(image_path: str, dark_thresh: int = 40) -> float:\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    return dark_ratio(img, dark_thresh)\n",
    "\n",
    "def analyse_folder_darkness(folder: str,\n",
    "                            dark_thresh: int = 40,\n",
    "                            csv_path: str | None = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        pct = image_dark_percent(os.path.join(folder, fname), dark_thresh) * 100\n",
    "        rows.append({\"image\": fname, \"dark_%\": pct})\n",
    "    df = pd.DataFrame(rows).sort_values(\"dark_%\", ascending=False)\n",
    "    if csv_path:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_with_boost(img: np.ndarray) -> np.ndarray:\n",
    "    img_boost = cv2.normalize(img, None, 255, 0, cv2.NORM_MINMAX)\n",
    "    img_boost = cv2.convertScaleAbs(img_boost, alpha=2.0, beta=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_clahe = clahe.apply(img_boost)\n",
    "    return img_clahe\n",
    "\n",
    "\n",
    "def tune_params(tile: np.ndarray,\n",
    "                low: float = 0.40,\n",
    "                mid: float = 0.20,\n",
    "                area_min_urban: float = 0.001) -> Tuple[float, float]:\n",
    "    dr = dark_ratio(tile)\n",
    "    if dr > low:\n",
    "        return area_min_urban / 5, 1.5\n",
    "    if dr > mid:\n",
    "        return area_min_urban / 2, 1.8\n",
    "    return area_min_urban, 2.2\n",
    "\n",
    "\n",
    "def merge_boxes(boxes: List[Tuple[int, int, int, int]], merge_distance: int = 10) -> List[Tuple[int, int, int, int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "    for i in range(len(boxes)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            x1_, y1_, x2_, y2_ = boxes[j]\n",
    "            if x1_ <= x2 + merge_distance and x2_ >= x1 - merge_distance and \\\n",
    "               y1_ <= y2 + merge_distance and y2_ >= y1 - merge_distance:\n",
    "                x1 = min(x1, x1_)\n",
    "                y1 = min(y1, y1_)\n",
    "                x2 = max(x2, x2_)\n",
    "                y2 = max(y2, y2_)\n",
    "                used[j] = True\n",
    "        merged.append((x1, y1, x2, y2))\n",
    "        used[i] = True\n",
    "    return merged\n",
    "\n",
    "\n",
    "def detect_objects_simple(img: np.ndarray,\n",
    "                          area_thresh: float = 500,\n",
    "                          min_mean_brightness: int = 40) -> List[Tuple[int, int, int, int]]:\n",
    "    # Никакого буста\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img)\n",
    "\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, -5)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k)\n",
    "\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    objs = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "        area = bw * bh\n",
    "        if area < area_thresh:\n",
    "            continue\n",
    "        mean_val = cv2.mean(img[y:y+bh, x:x+bw])[0]\n",
    "        if mean_val < min_mean_brightness:\n",
    "            continue\n",
    "        objs.append((x, y, x + bw, y + bh))\n",
    "\n",
    "    return merge_boxes(objs, merge_distance=10)\n",
    "\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tw, th = max_tile_size\n",
    "    tiles = []\n",
    "    for y in range(0, h, th):\n",
    "        for x in range(0, w, tw):\n",
    "            tiles.append((image[y:y + th, x:x + tw], x, y))\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def process_image(image_path: str,\n",
    "                  max_tile_size=(2000, 2000),\n",
    "                  low: float = 0.40,\n",
    "                  mid: float = 0.20,\n",
    "                  area_min: float = 0.001):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    boxes = []\n",
    "    for tile, xo, yo in split_image(img, max_tile_size):\n",
    "        area_t, ratio_t = tune_params(tile, low, mid, area_min)\n",
    "        for x1, y1, x2, y2 in detect_objects(tile, area_t, ratio_t):\n",
    "            boxes.append((x1 + xo, y1 + yo, x2 + xo, y2 + yo))\n",
    "    return merge_boxes(boxes)\n",
    "\n",
    "\n",
    "def draw_objects(image_path: str, objects, output_path: str):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        color = (0, 0, 255)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "\n",
    "def process_folder(input_folder: str,\n",
    "                   output_folder: str,\n",
    "                   max_tile_size=(2000, 2000),\n",
    "                   low: float = 0.40,\n",
    "                   mid: float = 0.20,\n",
    "                   area_min: float = 0.001):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "        pct_dark = image_dark_percent(inp) * 100\n",
    "        if pct_dark > low * 100:\n",
    "            scene = \"water-heavy\"\n",
    "        elif pct_dark > mid * 100:\n",
    "            scene = \"mixed\"\n",
    "        else:\n",
    "            scene = \"urban\"\n",
    "        print(f\"{fname}: dark {pct_dark:.1f}% → {scene} params\")\n",
    "        boxes = process_image(inp, max_tile_size, low, mid, area_min)\n",
    "        out_img = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        draw_objects(inp, boxes, out_img)\n",
    "\n",
    "        box_df = pd.DataFrame(boxes, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "        box_df.to_csv(os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_boxes.csv\"), index=False)\n",
    "\n",
    "        summary.append({\n",
    "            \"image\": fname,\n",
    "            \"dark_%\": pct_dark,\n",
    "            \"objects\": len(boxes),\n",
    "            \"scene\": scene,\n",
    "            \"output\": out_img\n",
    "        })\n",
    "\n",
    "    if summary:\n",
    "        pd.DataFrame(summary).to_csv(os.path.join(output_folder, \"summary.csv\"), index=False)\n",
    "        print(\"CSV summary saved → summary.csv\")\n",
    "\n",
    "\n",
    "# Пример запуска\n",
    "# process_folder(input_folder=\"images\", output_folder=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609fa46",
   "metadata": {},
   "source": [
    "Что-то прям ебать какое хорошее 3 эпоха логика связана с тем что мы функцией preprocess_with_boost \"Заливаем\" фон изображения синим для контрастности точек инетерса и работаем исключительно по ним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6057846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dark_ratio(img: np.ndarray, dark_thresh: int = 40) -> float:\n",
    "    return float((img < dark_thresh).sum()) / img.size\n",
    "\n",
    "def image_dark_percent(image_path: str, dark_thresh: int = 40) -> float:\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    return dark_ratio(img, dark_thresh)\n",
    "\n",
    "def analyse_folder_darkness(folder: str,\n",
    "                            dark_thresh: int = 40,\n",
    "                            csv_path: str | None = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        pct = image_dark_percent(os.path.join(folder, fname), dark_thresh) * 100\n",
    "        rows.append({\"image\": fname, \"dark_%\": pct})\n",
    "    df = pd.DataFrame(rows).sort_values(\"dark_%\", ascending=False)\n",
    "    if csv_path:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_with_boost(img: np.ndarray) -> np.ndarray:\n",
    "    img_boost = cv2.normalize(img, None, 255, 0, cv2.NORM_MINMAX)\n",
    "    img_boost = cv2.convertScaleAbs(img_boost, alpha=2.0, beta=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_clahe = clahe.apply(img_boost)\n",
    "    return img_clahe\n",
    "\n",
    "\n",
    "def tune_params(tile: np.ndarray,\n",
    "                low: float = 0.40,\n",
    "                mid: float = 0.20,\n",
    "                area_min_urban: float = 0.001) -> Tuple[float, float]:\n",
    "    dr = dark_ratio(tile)\n",
    "    if dr > low:\n",
    "        return area_min_urban / 5, 1.5\n",
    "    if dr > mid:\n",
    "        return area_min_urban / 2, 1.8\n",
    "    return area_min_urban, 2.2\n",
    "\n",
    "\n",
    "def merge_boxes(boxes: List[Tuple[int, int, int, int]], merge_distance: int = 10) -> List[Tuple[int, int, int, int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "    for i in range(len(boxes)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            x1_, y1_, x2_, y2_ = boxes[j]\n",
    "            if x1_ <= x2 + merge_distance and x2_ >= x1 - merge_distance and \\\n",
    "               y1_ <= y2 + merge_distance and y2_ >= y1 - merge_distance:\n",
    "                x1 = min(x1, x1_)\n",
    "                y1 = min(y1, y1_)\n",
    "                x2 = max(x2, x2_)\n",
    "                y2 = max(y2, y2_)\n",
    "                used[j] = True\n",
    "        merged.append((x1, y1, x2, y2))\n",
    "        used[i] = True\n",
    "    return merged\n",
    "\n",
    "def detect_objects(tile: np.ndarray,\n",
    "                   area_thresh: float,\n",
    "                   intensity_ratio: float,\n",
    "                   min_mean_brightness: int = 40) -> List[Tuple[int, int, int, int]]:\n",
    "    img = preprocess_with_boost(tile)\n",
    "\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, -5)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k)\n",
    "\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    objs = []\n",
    "    for cnt in contours:\n",
    "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "        area = bw * bh\n",
    "        if area < 400:\n",
    "            continue\n",
    "        aspect = max(bw / bh, bh / bw)\n",
    "        if aspect > 15:\n",
    "            continue\n",
    "        compactness = area / (4 * np.pi * ((bw / 2 + bh / 2)**2))\n",
    "        if compactness < 0.01:\n",
    "            continue\n",
    "\n",
    "        # Отсекаем совсем тёмные объекты по средней яркости\n",
    "        mean_val = cv2.mean(img[y:y+bh, x:x+bw])[0]\n",
    "        if mean_val < min_mean_brightness:\n",
    "            continue\n",
    "\n",
    "        objs.append((x, y, x + bw, y + bh))\n",
    "\n",
    "    return merge_boxes(objs)\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tw, th = max_tile_size\n",
    "    tiles = []\n",
    "    for y in range(0, h, th):\n",
    "        for x in range(0, w, tw):\n",
    "            tiles.append((image[y:y + th, x:x + tw], x, y))\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def process_image(image_path: str,\n",
    "                  max_tile_size=(2000, 2000),\n",
    "                  low: float = 0.40,\n",
    "                  mid: float = 0.20,\n",
    "                  area_min: float = 0.001,\n",
    "                  min_mean_brightness: int = 40):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    boxes = []\n",
    "    for tile, xo, yo in split_image(img, max_tile_size):\n",
    "        area_t, ratio_t = tune_params(tile, low, mid, area_min)\n",
    "        for x1, y1, x2, y2 in detect_objects(tile, area_t, ratio_t, min_mean_brightness):\n",
    "            boxes.append((x1 + xo, y1 + yo, x2 + xo, y2 + yo))\n",
    "    return merge_boxes(boxes)\n",
    "\n",
    "\n",
    "def detect_water_contours(img: np.ndarray, threshold: int = 50) -> List[np.ndarray]:\n",
    "    \"\"\"Возвращает контуры темных (водных) участков.\"\"\"\n",
    "    gray = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_objects(image_path: str, objects, output_path: str):\n",
    "    img_gray = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    img_color = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Объекты интереса\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(img_color, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # Контуры воды\n",
    "    contours = detect_water_contours(img_gray)\n",
    "    cv2.drawContours(img_color, contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "    cv2.imwrite(output_path, img_color)\n",
    "\n",
    "\n",
    "def process_folder(input_folder: str,\n",
    "                   output_folder: str,\n",
    "                   max_tile_size=(2000, 2000),\n",
    "                   low: float = 0.40,\n",
    "                   mid: float = 0.20,\n",
    "                   area_min: float = 0.001):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "        pct_dark = image_dark_percent(inp) * 100\n",
    "        if pct_dark > low * 100:\n",
    "            scene = \"water-heavy\"\n",
    "        elif pct_dark > mid * 100:\n",
    "            scene = \"mixed\"\n",
    "        else:\n",
    "            scene = \"urban\"\n",
    "        print(f\"{fname}: dark {pct_dark:.1f}% → {scene} params\")\n",
    "        boxes = process_image(inp, max_tile_size, low, mid, area_min)\n",
    "        out_img = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        draw_objects(inp, boxes, out_img)\n",
    "\n",
    "        box_df = pd.DataFrame(boxes, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "        box_df.to_csv(os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_boxes.csv\"), index=False)\n",
    "\n",
    "        summary.append({\n",
    "            \"image\": fname,\n",
    "            \"dark_%\": pct_dark,\n",
    "            \"objects\": len(boxes),\n",
    "            \"scene\": scene,\n",
    "            \"output\": out_img\n",
    "        })\n",
    "\n",
    "    if summary:\n",
    "        pd.DataFrame(summary).to_csv(os.path.join(output_folder, \"summary.csv\"), index=False)\n",
    "        print(\"CSV summary saved → summary.csv\")\n",
    "\n",
    "\n",
    "# Пример запуска\n",
    "# process_folder(input_folder=\"images\", output_folder=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5e9346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.jpg: dark 63.9% → water-heavy params\n",
      "9.jpg: dark 96.1% → water-heavy params\n",
      "4.jpg: dark 34.6% → mixed params\n",
      "5.jpg: dark 56.6% → water-heavy params\n",
      "7.jpg: dark 31.3% → mixed params\n",
      "6.jpg: dark 71.4% → water-heavy params\n",
      "2.jpg: dark 61.4% → water-heavy params\n",
      "3.jpg: dark 33.7% → mixed params\n",
      "1.jpg: dark 68.9% → water-heavy params\n",
      "CSV summary saved → summary.csv\n"
     ]
    }
   ],
   "source": [
    "process_folder(\n",
    "    input_folder=\"images\",\n",
    "    output_folder=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f25a3",
   "metadata": {},
   "source": [
    "Эпоха 4 - Развиваем историю Эпохи три, только меняем фон на фулл черный + добавляем работу двойной алгоритм, где мы работаем с заливкой а затем просто с обычным изображением, мержим все найденные точки и фиксируем прибыль, если алгос не нашел объект - я его маму шатал (Ниже два алгоса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4f3e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def dark_ratio(img: np.ndarray, dark_thresh: int = 40) -> float:\n",
    "    return float((img < dark_thresh).sum()) / img.size\n",
    "\n",
    "def image_dark_percent(image_path: str, dark_thresh: int = 40) -> float:\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    return dark_ratio(img, dark_thresh)\n",
    "\n",
    "def analyse_folder_darkness(folder: str,\n",
    "                            dark_thresh: int = 40,\n",
    "                            csv_path: str | None = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        pct = image_dark_percent(os.path.join(folder, fname), dark_thresh) * 100\n",
    "        rows.append({\"image\": fname, \"dark_%\": pct})\n",
    "    df = pd.DataFrame(rows).sort_values(\"dark_%\", ascending=False)\n",
    "    if csv_path:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "def preprocess_with_boost(img: np.ndarray) -> np.ndarray:\n",
    "    # Усиление контраста\n",
    "    img_boost = cv2.normalize(img, None, 255, 0, cv2.NORM_MINMAX)\n",
    "    img_boost = cv2.convertScaleAbs(img_boost, alpha=2.0, beta=50)\n",
    "\n",
    "    # CLAHE улучшает локальный контраст\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_clahe = clahe.apply(img_boost)\n",
    "\n",
    "    # Заливка тёмного в ноль\n",
    "    _, img_black_bg = cv2.threshold(img_clahe, 60, 255, cv2.THRESH_TOZERO)\n",
    "    # img_boost = cv2.normalize(img, None, 255, 0, cv2.NORM_MINMAX)\n",
    "    # img_boost = cv2.convertScaleAbs(img_boost, alpha=2.0, beta=50)\n",
    "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    # img_clahe = clahe.apply(img_boost)\n",
    "\n",
    "    # ⚠️ Сохраняем для отладки (можно убрать позже)\n",
    "    cv2.imwrite(\"debug_preprocessed.png\", img_clahe)\n",
    "\n",
    "    return img_clahe\n",
    "\n",
    "def tune_params(tile: np.ndarray,\n",
    "                low: float = 0.40,\n",
    "                mid: float = 0.20,\n",
    "                area_min_urban: float = 0.001) -> Tuple[float, float]:\n",
    "    dr = dark_ratio(tile)\n",
    "    if dr > low:\n",
    "        return area_min_urban / 5, 1.5\n",
    "    if dr > mid:\n",
    "        return area_min_urban / 2, 1.8\n",
    "    return area_min_urban, 2.2\n",
    "\n",
    "\n",
    "def merge_boxes(boxes: List[Tuple[int, int, int, int]], merge_distance: int = 10) -> List[Tuple[int, int, int, int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "    for i in range(len(boxes)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            x1_, y1_, x2_, y2_ = boxes[j]\n",
    "            if x1_ <= x2 + merge_distance and x2_ >= x1 - merge_distance and \\\n",
    "               y1_ <= y2 + merge_distance and y2_ >= y1 - merge_distance:\n",
    "                x1 = min(x1, x1_)\n",
    "                y1 = min(y1, y1_)\n",
    "                x2 = max(x2, x2_)\n",
    "                y2 = max(y2, y2_)\n",
    "                used[j] = True\n",
    "        merged.append((x1, y1, x2, y2))\n",
    "        used[i] = True\n",
    "    return merged\n",
    "\n",
    "def detect_objects(tile: np.ndarray,\n",
    "                   area_thresh: float,\n",
    "                   intensity_ratio: float,\n",
    "                   min_mean_brightness: int = 40) -> List[Tuple[int, int, int, int]]:\n",
    "    img = preprocess_with_boost(tile)\n",
    "\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, -5)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k)\n",
    "\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    objs = []\n",
    "    for cnt in contours:\n",
    "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "        area = bw * bh\n",
    "        if area < 400:\n",
    "            continue\n",
    "        aspect = max(bw / bh, bh / bw)\n",
    "        if aspect > 15:\n",
    "            continue\n",
    "        compactness = area / (4 * np.pi * ((bw / 2 + bh / 2)**2))\n",
    "        if compactness < 0.01:\n",
    "            continue\n",
    "\n",
    "        # Отсекаем совсем тёмные объекты по средней яркости\n",
    "        mean_val = cv2.mean(img[y:y+bh, x:x+bw])[0]\n",
    "        if mean_val < min_mean_brightness:\n",
    "            continue\n",
    "\n",
    "        objs.append((x, y, x + bw, y + bh))\n",
    "\n",
    "    return merge_boxes(objs)\n",
    "\n",
    "def detect_objects_simple(img: np.ndarray,\n",
    "                          area_thresh: float = 500,\n",
    "                          min_mean_brightness: int = 40) -> List[Tuple[int, int, int, int]]:\n",
    "    # Никакого буста\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img)\n",
    "\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, -5)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k)\n",
    "\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    objs = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "        area = bw * bh\n",
    "        if area < area_thresh:\n",
    "            continue\n",
    "        mean_val = cv2.mean(img[y:y+bh, x:x+bw])[0]\n",
    "        if mean_val < min_mean_brightness:\n",
    "            continue\n",
    "        objs.append((x, y, x + bw, y + bh))\n",
    "\n",
    "    return merge_boxes(objs, merge_distance=10)\n",
    "\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tw, th = max_tile_size\n",
    "    tiles = []\n",
    "    for y in range(0, h, th):\n",
    "        for x in range(0, w, tw):\n",
    "            tiles.append((image[y:y + th, x:x + tw], x, y))\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def process_image_combined(image_path: str,\n",
    "                           area_min: float = 0.001,\n",
    "                           min_mean_brightness: int = 40):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    h, w = img.shape\n",
    "    area_thresh = h * w * area_min\n",
    "\n",
    "    # Старый метод\n",
    "    area_t, ratio_t = tune_params(img)\n",
    "    boxes_a = detect_objects(img, area_t, ratio_t, min_mean_brightness)\n",
    "\n",
    "    # Новый метод без тюна\n",
    "    boxes_b = detect_objects_simple(img, area_thresh, min_mean_brightness)\n",
    "\n",
    "    # Объединяем\n",
    "    merged = merge_boxes(boxes_a + boxes_b, merge_distance=15)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "def detect_water_contours(img: np.ndarray, threshold: int = 50) -> List[np.ndarray]:\n",
    "    \"\"\"Возвращает контуры темных (водных) участков.\"\"\"\n",
    "    gray = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_objects(image_path: str, objects, output_path: str):\n",
    "    img_gray = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    img_color = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Объекты интереса\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(img_color, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # Контуры воды\n",
    "    contours = detect_water_contours(img_gray)\n",
    "    cv2.drawContours(img_color, contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "    cv2.imwrite(output_path, img_color)\n",
    "\n",
    "\n",
    "def process_folder(input_folder: str,\n",
    "                   output_folder: str,\n",
    "                   max_tile_size=(2000, 2000),\n",
    "                   low: float = 0.40,\n",
    "                   mid: float = 0.20,\n",
    "                   area_min: float = 0.001):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "        pct_dark = image_dark_percent(inp) * 100\n",
    "        if pct_dark > low * 100:\n",
    "            scene = \"water-heavy\"\n",
    "        elif pct_dark > mid * 100:\n",
    "            scene = \"mixed\"\n",
    "        else:\n",
    "            scene = \"urban\"\n",
    "        print(f\"{fname}: dark {pct_dark:.1f}% → {scene} params\")\n",
    "        boxes = boxes = process_image_combined(inp, area_min=area_min)\n",
    "        \n",
    "        out_img = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        draw_objects(inp, boxes, out_img)\n",
    "\n",
    "        box_df = pd.DataFrame(boxes, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "        box_df.to_csv(os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_boxes.csv\"), index=False)\n",
    "\n",
    "        summary.append({\n",
    "            \"image\": fname,\n",
    "            \"dark_%\": pct_dark,\n",
    "            \"objects\": len(boxes),\n",
    "            \"scene\": scene,\n",
    "            \"output\": out_img\n",
    "        })\n",
    "\n",
    "    if summary:\n",
    "        pd.DataFrame(summary).to_csv(os.path.join(output_folder, \"summary.csv\"), index=False)\n",
    "        print(\"CSV summary saved → summary.csv\")\n",
    "\n",
    "\n",
    "# Пример запуска\n",
    "# process_folder(input_folder=\"images\", output_folder=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ca095521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.jpg: dark 63.9% → water-heavy params\n",
      "9.jpg: dark 96.1% → water-heavy params\n",
      "4.jpg: dark 34.6% → mixed params\n",
      "5.jpg: dark 56.6% → water-heavy params\n",
      "7.jpg: dark 31.3% → mixed params\n",
      "6.jpg: dark 71.4% → water-heavy params\n",
      "2.jpg: dark 61.4% → water-heavy params\n",
      "3.jpg: dark 33.7% → mixed params\n",
      "1.jpg: dark 68.9% → water-heavy params\n",
      "CSV summary saved → summary.csv\n"
     ]
    }
   ],
   "source": [
    "process_folder(\n",
    "    input_folder=\"images\",\n",
    "    output_folder=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a3b4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dark_ratio(img: np.ndarray, dark_thresh: int = 40) -> float:\n",
    "    return float((img < dark_thresh).sum()) / img.size\n",
    "\n",
    "def image_dark_percent(image_path: str, dark_thresh: int = 40) -> float:\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    return dark_ratio(img, dark_thresh)\n",
    "\n",
    "def analyse_folder_darkness(folder: str,\n",
    "                            dark_thresh: int = 40,\n",
    "                            csv_path: str | None = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        pct = image_dark_percent(os.path.join(folder, fname), dark_thresh) * 100\n",
    "        rows.append({\"image\": fname, \"dark_%\": pct})\n",
    "    df = pd.DataFrame(rows).sort_values(\"dark_%\", ascending=False)\n",
    "    if csv_path:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "def preprocess_with_boost(img: np.ndarray) -> np.ndarray:\n",
    "    # Усиление контраста\n",
    "    img_boost = cv2.normalize(img, None, 255, 0, cv2.NORM_MINMAX)\n",
    "    img_boost = cv2.convertScaleAbs(img_boost, alpha=2.0, beta=50)\n",
    "\n",
    "    # CLAHE улучшает локальный контраст\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_clahe = clahe.apply(img_boost)\n",
    "\n",
    "    # Заливка тёмного в ноль\n",
    "    _, img_black_bg = cv2.threshold(img_clahe, 60, 255, cv2.THRESH_TOZERO)\n",
    "    # img_boost = cv2.normalize(img, None, 255, 0, cv2.NORM_MINMAX)\n",
    "    # img_boost = cv2.convertScaleAbs(img_boost, alpha=2.0, beta=50)\n",
    "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    # img_clahe = clahe.apply(img_boost)\n",
    "\n",
    "    # ⚠️ Сохраняем для отладки (можно убрать позже)\n",
    "    cv2.imwrite(\"debug_preprocessed.png\", img_clahe)\n",
    "\n",
    "    return img_clahe\n",
    "\n",
    "def tune_params(tile: np.ndarray,\n",
    "                low: float = 0.40,\n",
    "                mid: float = 0.20,\n",
    "                area_min_urban: float = 0.001) -> Tuple[float, float]:\n",
    "    dr = dark_ratio(tile)\n",
    "    if dr > low:\n",
    "        return area_min_urban / 5, 1.5\n",
    "    if dr > mid:\n",
    "        return area_min_urban / 2, 1.8\n",
    "    return area_min_urban, 2.2\n",
    "\n",
    "\n",
    "def merge_boxes(boxes: List[Tuple[int, int, int, int]], merge_distance: int = 10) -> List[Tuple[int, int, int, int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "    for i in range(len(boxes)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            x1_, y1_, x2_, y2_ = boxes[j]\n",
    "            if x1_ <= x2 + merge_distance and x2_ >= x1 - merge_distance and \\\n",
    "               y1_ <= y2 + merge_distance and y2_ >= y1 - merge_distance:\n",
    "                x1 = min(x1, x1_)\n",
    "                y1 = min(y1, y1_)\n",
    "                x2 = max(x2, x2_)\n",
    "                y2 = max(y2, y2_)\n",
    "                used[j] = True\n",
    "        merged.append((x1, y1, x2, y2))\n",
    "        used[i] = True\n",
    "    return merged\n",
    "\n",
    "def detect_objects(tile: np.ndarray,\n",
    "                   area_thresh: float,\n",
    "                   intensity_ratio: float,\n",
    "                   min_mean_brightness: int = 40) -> List[Tuple[int, int, int, int]]:\n",
    "    img = preprocess_with_boost(tile)\n",
    "\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, -5)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k)\n",
    "\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    objs = []\n",
    "    for cnt in contours:\n",
    "        x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "        area = bw * bh\n",
    "        if area < 400:\n",
    "            continue\n",
    "        aspect = max(bw / bh, bh / bw)\n",
    "        if aspect > 15:\n",
    "            continue\n",
    "        compactness = area / (4 * np.pi * ((bw / 2 + bh / 2)**2))\n",
    "        if compactness < 0.01:\n",
    "            continue\n",
    "\n",
    "        # Отсекаем совсем тёмные объекты по средней яркости\n",
    "        mean_val = cv2.mean(img[y:y+bh, x:x+bw])[0]\n",
    "        if mean_val < min_mean_brightness:\n",
    "            continue\n",
    "\n",
    "        objs.append((x, y, x + bw, y + bh))\n",
    "\n",
    "    return merge_boxes(objs)\n",
    "\n",
    "def detect_objects_advanced(tile: np.ndarray,\n",
    "                            area_thresh: float = 0.001,\n",
    "                            intensity_ratio: float = 2.0):\n",
    "    pre = preprocess(tile)\n",
    "\n",
    "    # adaptive threshold tuned for speckle\n",
    "    bin_img = cv2.adaptiveThreshold(pre, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 51, -5)\n",
    "\n",
    "    # morphology to remove pepper noise and fill holes\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    labeled, num = label(bin_img)\n",
    "    objs = []\n",
    "    min_pixels = int(area_thresh * tile.shape[0] * tile.shape[1])\n",
    "    background_median = np.median(tile)\n",
    "\n",
    "    for i in range(1, num + 1):\n",
    "        ys, xs = np.where(labeled == i)\n",
    "        if xs.size < min_pixels:\n",
    "            continue\n",
    "        if tile[ys, xs].mean() < intensity_ratio * background_median:\n",
    "            continue\n",
    "        x1, x2 = xs.min(), xs.max()\n",
    "        y1, y2 = ys.min(), ys.max()\n",
    "        objs.append((x1, y1, x2, y2))\n",
    "    return objs\n",
    "\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tw, th = max_tile_size\n",
    "    tiles = []\n",
    "    for y in range(0, h, th):\n",
    "        for x in range(0, w, tw):\n",
    "            tiles.append((image[y:y + th, x:x + tw], x, y))\n",
    "    return tiles\n",
    "\n",
    "\n",
    "def process_image_combined(image_path: str,\n",
    "                           area_min: float = 0.001,\n",
    "                           min_mean_brightness: int = 40):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    h, w = img.shape\n",
    "    area_thresh = h * w * area_min\n",
    "\n",
    "    # Старый метод\n",
    "    area_t, ratio_t = tune_params(img)\n",
    "    boxes_a = detect_objects(img, area_t, ratio_t, min_mean_brightness)\n",
    "\n",
    "    # Новый метод без тюна\n",
    "    boxes_b = detect_objects_simple(img, area_thresh, min_mean_brightness)\n",
    "\n",
    "    # Объединяем\n",
    "    merged = merge_boxes(boxes_a + boxes_b, merge_distance=15)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "def detect_water_contours(img: np.ndarray, threshold: int = 50) -> List[np.ndarray]:\n",
    "    \"\"\"Возвращает контуры темных (водных) участков.\"\"\"\n",
    "    gray = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    _, mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_objects(image_path: str, objects, output_path: str):\n",
    "    img_gray = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    img_color = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Объекты интереса\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(img_color, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # Контуры воды\n",
    "    contours = detect_water_contours(img_gray)\n",
    "    cv2.drawContours(img_color, contours, -1, (255, 0, 0), 1)\n",
    "\n",
    "    cv2.imwrite(output_path, img_color)\n",
    "\n",
    "\n",
    "def process_folder(input_folder: str,\n",
    "                   output_folder: str,\n",
    "                   max_tile_size=(2000, 2000),\n",
    "                   low: float = 0.40,\n",
    "                   mid: float = 0.20,\n",
    "                   area_min: float = 0.001):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "        pct_dark = image_dark_percent(inp) * 100\n",
    "        if pct_dark > low * 100:\n",
    "            scene = \"water-heavy\"\n",
    "        elif pct_dark > mid * 100:\n",
    "            scene = \"mixed\"\n",
    "        else:\n",
    "            scene = \"urban\"\n",
    "        ##print(f\"{fname}: dark {pct_dark:.1f}% → {scene} params\")\n",
    "        boxes = boxes = process_image_combined(inp, area_min=area_min)\n",
    "        \n",
    "        out_img = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        draw_objects(inp, boxes, out_img)\n",
    "\n",
    "        box_df = pd.DataFrame(boxes, columns=['x1', 'y1', 'x2', 'y2'])\n",
    "        box_df.to_csv(os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_boxes.csv\"), index=False)\n",
    "\n",
    "        summary.append({\n",
    "            \"image\": fname,\n",
    "            \"dark_%\": pct_dark,\n",
    "            \"objects\": len(boxes),\n",
    "            \"scene\": scene,\n",
    "            \"output\": out_img\n",
    "        })\n",
    "\n",
    "    if summary:\n",
    "        pd.DataFrame(summary).to_csv(os.path.join(output_folder, \"summary.csv\"), index=False)\n",
    "        ##print(\"CSV summary saved → summary.csv\")\n",
    "\n",
    "\n",
    "# Пример запуска\n",
    "process_folder(input_folder=\"images\", output_folder=\"output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
