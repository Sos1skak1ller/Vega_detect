{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from opencv-python) (2.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from scipy) (2.2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from scipy) (2.2.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-macosx_10_13_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kushnikov/Desktop/Practice_vega/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-macosx_10_13_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install opencv-python\n",
    "%pip install scipy\n",
    "%pip install scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЭТО ПРОРЫВ НО Я ХОЧУ ЕЩЕ - Кластеризация работает, но на воде есть процентаж ошибок(не находит корабли)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Pre‑processing\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def preprocess(img: np.ndarray,\n",
    "               brightness: float = 1.3,\n",
    "               clahe_clip: float = 2.0,\n",
    "               denoise_h: int = 20) -> np.ndarray:\n",
    "    # stretch to [0,255]\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # global brightness / contrast knob\n",
    "    img = cv2.convertScaleAbs(img, alpha=brightness, beta=0)\n",
    "    # local contrast equalisation\n",
    "    clahe = cv2.createCLAHE(clipLimit=clahe_clip, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img)\n",
    "    # fast non‑local means denoise (good on speckle)\n",
    "    img = cv2.fastNlMeansDenoising(img, None, h=denoise_h,\n",
    "                                   templateWindowSize=7, searchWindowSize=21)\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Object detection on a single tile\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def detect_objects_advanced(tile: np.ndarray,\n",
    "                            area_thresh: float = 0.001,\n",
    "                            intensity_ratio: float = 2.0):\n",
    "    pre = preprocess(tile)\n",
    "\n",
    "    # adaptive threshold tuned for speckle\n",
    "    bin_img = cv2.adaptiveThreshold(pre, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 51, -5)\n",
    "\n",
    "    # morphology to remove pepper noise and fill holes\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    labeled, num = label(bin_img)\n",
    "    objs = []\n",
    "    min_pixels = int(area_thresh * tile.shape[0] * tile.shape[1])\n",
    "    background_median = np.median(tile)\n",
    "\n",
    "    for i in range(1, num + 1):\n",
    "        ys, xs = np.where(labeled == i)\n",
    "        if xs.size < min_pixels:\n",
    "            continue\n",
    "        if tile[ys, xs].mean() < intensity_ratio * background_median:\n",
    "            continue\n",
    "        x1, x2 = xs.min(), xs.max()\n",
    "        y1, y2 = ys.min(), ys.max()\n",
    "        objs.append((x1, y1, x2, y2))\n",
    "    return objs\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Tiling helpers (to avoid huge memory)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tile_w = min(w, max_tile_size[0])\n",
    "    tile_h = min(h, max_tile_size[1])\n",
    "    tiles = []\n",
    "    for y in range(0, h, tile_h):\n",
    "        for x in range(0, w, tile_w):\n",
    "            tiles.append((image[y:y + tile_h, x:x + tile_w], x, y))\n",
    "    return tiles\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. High‑level wrappers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def process_image_adv(image_path: str,\n",
    "                      max_tile_size=(2000, 2000),\n",
    "                      area_thresh: float = 0.001,\n",
    "                      intensity_ratio: float = 2.0):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8),\n",
    "                       cv2.IMREAD_GRAYSCALE)\n",
    "    tiles = split_image(img, max_tile_size)\n",
    "    all_objects = []\n",
    "    for tile, x_off, y_off in tiles:\n",
    "        objs = detect_objects_advanced(tile, area_thresh, intensity_ratio)\n",
    "        for x1, y1, x2, y2 in objs:\n",
    "            all_objects.append((x1 + x_off, y1 + y_off,\n",
    "                                x2 + x_off, y2 + y_off))\n",
    "    return all_objects\n",
    "\n",
    "\n",
    "def draw_objects(image_path: str, objects, output_path: str):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8),\n",
    "                       cv2.IMREAD_COLOR)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "\n",
    "def process_folder(input_folder: str,\n",
    "                   output_folder: str,\n",
    "                   max_tile_size=(2000, 2000),\n",
    "                   area_thresh: float = 0.001,\n",
    "                   intensity_ratio: float = 2.0):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "        out = os.path.join(output_folder,\n",
    "                           f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        objs = process_image_adv(inp, max_tile_size,\n",
    "                                 area_thresh, intensity_ratio)\n",
    "        draw_objects(inp, objs, out)\n",
    "        summary.append({\"image\": fname,\n",
    "                        \"objects_detected\": len(objs),\n",
    "                        \"output_image\": out})\n",
    "        print(f\"Processed {fname}: {len(objs)} objects -> {out}\")\n",
    "\n",
    "    # optional CSV summary\n",
    "    if summary:\n",
    "        df = pd.DataFrame(summary)\n",
    "        df.to_csv(os.path.join(output_folder, \"summary.csv\"), index=False)\n",
    "        print(f\"CSV summary saved to {output_folder}/summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРОБА ПЕРА (Пробуем прокидывать параметры исходя из процента черноты) - Тут проблема исключительно в том, что на воде он выделяет шум как объекты с этим надо что-то придумать Решение в tune_params - по играться с параметрами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.jpg: dark 63.9% → water‑heavy params\n",
      "9.jpg: dark 96.1% → water‑heavy params\n",
      "4.jpg: dark 34.6% → mixed params\n",
      "5.jpg: dark 56.6% → water‑heavy params\n",
      "7.jpg: dark 31.3% → mixed params\n",
      "6.jpg: dark 71.4% → water‑heavy params\n",
      "2.jpg: dark 61.4% → water‑heavy params\n",
      "3.jpg: dark 33.7% → mixed params\n",
      "1.jpg: dark 68.9% → water‑heavy params\n",
      "CSV summary saved → summary.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import argparse\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Darkness metrics\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def dark_ratio(img: np.ndarray, dark_thresh: int = 40) -> float:\n",
    "    \"\"\"Return fraction of pixels darker than *dark_thresh* (0‑255).\"\"\"\n",
    "    return float((img < dark_thresh).sum()) / img.size\n",
    "\n",
    "\n",
    "def image_dark_percent(image_path: str, dark_thresh: int = 40) -> float:\n",
    "    \"\"\"Decode image from disk and return percentage of dark pixels (0‑1).\"\"\"\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8),\n",
    "                       cv2.IMREAD_GRAYSCALE)\n",
    "    return dark_ratio(img, dark_thresh)\n",
    "\n",
    "\n",
    "def analyse_folder_darkness(folder: str,\n",
    "                            dark_thresh: int = 40,\n",
    "                            csv_path: str | None = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        pct = image_dark_percent(os.path.join(folder, fname), dark_thresh) * 100\n",
    "        rows.append({\"image\": fname, \"dark_%\": pct})\n",
    "    df = pd.DataFrame(rows).sort_values(\"dark_%\", ascending=False)\n",
    "    if csv_path:\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Pre‑processing\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def preprocess(img: np.ndarray,\n",
    "               brightness: float = 1.3,\n",
    "               clahe_clip: float = 2.0,\n",
    "               denoise_h: int = 20) -> np.ndarray:\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    img = cv2.convertScaleAbs(img, alpha=brightness, beta=0)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clahe_clip, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img)\n",
    "    img = cv2.fastNlMeansDenoising(img, None, h=denoise_h,\n",
    "                                   templateWindowSize=7, searchWindowSize=21)\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Adaptive parameter tuning per tile\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def tune_params(tile: np.ndarray,\n",
    "                low: float = 0.40,\n",
    "                mid: float = 0.20,\n",
    "                area_min_urban: float = 0.001) -> Tuple[float, float]:\n",
    "    dr = dark_ratio(tile)\n",
    "    if dr > low:       # water‑heavy (mostly dark)\n",
    "        return area_min_urban / 5, 1.5\n",
    "    if dr > mid:       # mixed\n",
    "        return area_min_urban / 2, 1.8\n",
    "    return area_min_urban, 2.2  # urban / bright\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. Detection on a tile\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def detect_objects(tile: np.ndarray,\n",
    "                   area_thresh: float,\n",
    "                   intensity_ratio: float) -> List[Tuple[int, int, int, int]]:\n",
    "    pre = preprocess(tile)\n",
    "    bin_img = cv2.adaptiveThreshold(pre, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 51, -5)\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, k, iterations=2)\n",
    "\n",
    "    labeled, num = label(bin_img)\n",
    "    objs = []\n",
    "    min_pixels = int(area_thresh * tile.shape[0] * tile.shape[1])\n",
    "    bg_med = np.median(tile)\n",
    "\n",
    "    for i in range(1, num + 1):\n",
    "        ys, xs = np.where(labeled == i)\n",
    "        if xs.size < min_pixels:\n",
    "            continue\n",
    "        if tile[ys, xs].mean() < intensity_ratio * bg_med:\n",
    "            continue\n",
    "        objs.append((xs.min(), ys.min(), xs.max(), ys.max()))\n",
    "    return objs\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. Tiling helper\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def split_image(image: np.ndarray, max_tile_size=(2000, 2000)):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    tw, th = max_tile_size\n",
    "    tiles = []\n",
    "    for y in range(0, h, th):\n",
    "        for x in range(0, w, tw):\n",
    "            tiles.append((image[y:y + th, x:x + tw], x, y))\n",
    "    return tiles\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6. High‑level wrappers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def process_image(image_path: str,\n",
    "                  max_tile_size=(2000, 2000),\n",
    "                  low: float = 0.40,\n",
    "                  mid: float = 0.20,\n",
    "                  area_min: float = 0.001):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8),\n",
    "                       cv2.IMREAD_GRAYSCALE)\n",
    "    boxes = []\n",
    "    for tile, xo, yo in split_image(img, max_tile_size):\n",
    "        area_t, ratio_t = tune_params(tile, low, mid, area_min)\n",
    "        for x1, y1, x2, y2 in detect_objects(tile, area_t, ratio_t):\n",
    "            boxes.append((x1 + xo, y1 + yo, x2 + xo, y2 + yo))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def draw_objects(image_path: str, objects, output_path: str):\n",
    "    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8),\n",
    "                       cv2.IMREAD_COLOR)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "\n",
    "def process_folder(input_folder: str,\n",
    "                   output_folder: str,\n",
    "                   max_tile_size=(2000, 2000),\n",
    "                   low: float = 0.40,\n",
    "                   mid: float = 0.20,\n",
    "                   area_min: float = 0.001):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    summary = []\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        inp = os.path.join(input_folder, fname)\n",
    "\n",
    "        # ---- darkness analysis ----\n",
    "        pct_dark = image_dark_percent(inp) * 100\n",
    "        if pct_dark > low * 100:\n",
    "            scene = \"water‑heavy\"\n",
    "        elif pct_dark > mid * 100:\n",
    "            scene = \"mixed\"\n",
    "        else:\n",
    "            scene = \"urban\"\n",
    "        print(f\"{fname}: dark {pct_dark:.1f}% → {scene} params\")\n",
    "\n",
    "        # ---- detection ----\n",
    "        boxes = process_image(inp, max_tile_size, low, mid, area_min)\n",
    "        out = os.path.join(output_folder, f\"{os.path.splitext(fname)[0]}_out.jpg\")\n",
    "        draw_objects(inp, boxes, out)\n",
    "        summary.append({\"image\": fname,\n",
    "                        \"dark_%\": pct_dark,\n",
    "                        \"objects\": len(boxes),\n",
    "                        \"scene\": scene,\n",
    "                        \"output\": out})\n",
    "\n",
    "    if summary:\n",
    "        pd.DataFrame(summary).to_csv(os.path.join(output_folder, \"summary.csv\"),\n",
    "                                     index=False)\n",
    "        print(\"CSV summary saved → summary.csv\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 7. CLI (defaults let you run with no flags)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Context‑aware SAR detector\")\n",
    "    parser.add_argument(\"--input\", default=\"./images\", help=\"Input folder with SAR images\")\n",
    "    parser.add_argument(\"--output\", default=\"./out\", help=\"Output folder for results\")\n",
    "    parser.add_argument(\"--tile\", type=int, default=2000, help=\"Max tile size (pixels)\")\n",
    "    parser.add_argument(\"--low\", type=float, default=0.40, help=\"Dark‑pixel ratio split for water‑heavy scene\")\n",
    "    parser.add_argument(\"--mid\", type=float, default=0.20, help=\"Dark‑pixel ratio split for mixed scene\")\n",
    "    parser.add_argument(\"--area_min\", type=float, default=0.001, help=\"Min blob area fraction for urban tiles\")\n",
    "    parser.add_argument(\"--brightness\", type=float, default=1.3, help=\"Global brightness gain (alpha)\")\n",
    "    parser.add_argument(\"--denoise\", type=int, default=20, help=\"fastNlMeans strength (higher = smoother)\")\n",
    "    args, _ = parser.parse_known_args()  # ignore extra args (e.g., Jupyter \"-f\")\n",
    "\n",
    "    # patch preprocess defaults according to CLI knobs\n",
    "    preprocess.__defaults__ = (args.brightness, 2.0, args.denoise)\n",
    "\n",
    "    process_folder(args.input, args.output,\n",
    "                   max_tile_size=(args.tile, args.tile),\n",
    "                   low=args.low, mid=args.mid, area_min=args.area_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.jpg: dark 63.9% → water‑heavy params\n",
      "9.jpg: dark 96.1% → water‑heavy params\n",
      "4.jpg: dark 34.6% → mixed params\n",
      "5.jpg: dark 56.6% → water‑heavy params\n",
      "7.jpg: dark 31.3% → mixed params\n",
      "6.jpg: dark 71.4% → water‑heavy params\n",
      "2.jpg: dark 61.4% → water‑heavy params\n",
      "3.jpg: dark 33.7% → mixed params\n",
      "1.jpg: dark 68.9% → water‑heavy params\n",
      "CSV summary saved → summary.csv\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"images\"\n",
    "output_folder = \"output\"\n",
    "process_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Без шума но очень криво"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_image(image, max_tile_size=(2000, 2000), overlap=100):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    \n",
    "    tile_size_x = min(w, max_tile_size[0])\n",
    "    tile_size_y = min(h, max_tile_size[1])\n",
    "    tiles = []\n",
    "    \n",
    "    for y in range(0, h, tile_size_y - overlap):\n",
    "        for x in range(0, w, tile_size_x - overlap):\n",
    "            tile = image[y:y + tile_size_y, x:x + tile_size_x]\n",
    "            tiles.append((tile, x, y))\n",
    "    \n",
    "    return tiles\n",
    "\n",
    "def detect_objects(image):\n",
    "    image = cv2.medianBlur(image, 5)\n",
    "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    objects = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        objects.append((x, y, x + w, y + h))\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def process_image(image_path, max_tile_size=(2000, 2000)):\n",
    "    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    tiles = split_image(image, max_tile_size)\n",
    "    all_objects = []\n",
    "    \n",
    "    for tile, x_offset, y_offset in tiles:\n",
    "        objects = detect_objects(tile)\n",
    "        adjusted_objects = [(x + x_offset, y + y_offset, x_max + x_offset, y_max + y_offset) \n",
    "                            for x, y, x_max, y_max in objects]\n",
    "        all_objects.extend(adjusted_objects)\n",
    "    \n",
    "    return all_objects\n",
    "\n",
    "def draw_objects(image_path, objects, output_path):\n",
    "    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def process_folder(input_folder, output_folder, max_tile_size=(2000, 2000)):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_out.bmp\")\n",
    "            \n",
    "            objects = process_image(input_path, max_tile_size)\n",
    "            draw_objects(input_path, objects, output_path)\n",
    "            print(f\"Processed: {filename} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что то неплохое "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_image(image, max_tile_size=(2000, 2000), overlap=100):\n",
    "    h, w = image.shape\n",
    "    if h <= max_tile_size[1] and w <= max_tile_size[0]:\n",
    "        return [(image, 0, 0)]\n",
    "    \n",
    "    tile_size_x = min(w, max_tile_size[0])\n",
    "    tile_size_y = min(h, max_tile_size[1])\n",
    "    tiles = []\n",
    "    \n",
    "    for y in range(0, h, tile_size_y - overlap):\n",
    "        for x in range(0, w, tile_size_x - overlap):\n",
    "            tile = image[y:y + tile_size_y, x:x + tile_size_x]\n",
    "            tiles.append((tile, x, y))\n",
    "    \n",
    "    return tiles\n",
    "\n",
    "def detect_objects(image):\n",
    "    image = cv2.medianBlur(image, 5)\n",
    "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bright_points = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bright_points.append((x + w // 2, y + h // 2))\n",
    "    \n",
    "    if bright_points:\n",
    "        bright_points = np.array(bright_points)\n",
    "        clustering = DBSCAN(eps=20, min_samples=2).fit(bright_points)\n",
    "        labels = clustering.labels_\n",
    "        \n",
    "        clusters = {}\n",
    "        for i, label in enumerate(labels):\n",
    "            if label != -1:\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append(bright_points[i])\n",
    "        \n",
    "        objects = []\n",
    "        for cluster in clusters.values():\n",
    "            cluster = np.array(cluster)\n",
    "            x_min, y_min = cluster.min(axis=0)\n",
    "            x_max, y_max = cluster.max(axis=0)\n",
    "            objects.append((x_min, y_min, x_max, y_max))\n",
    "        \n",
    "        return objects\n",
    "    \n",
    "    return []\n",
    "\n",
    "def process_image(image_path, max_tile_size=(2000, 2000)):\n",
    "    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "    tiles = split_image(image, max_tile_size)\n",
    "    all_objects = []\n",
    "    \n",
    "    for tile, x_offset, y_offset in tiles:\n",
    "        objects = detect_objects(tile)\n",
    "        adjusted_objects = [(x + x_offset, y + y_offset, x_max + x_offset, y_max + y_offset) \n",
    "                            for x, y, x_max, y_max in objects]\n",
    "        all_objects.extend(adjusted_objects)\n",
    "    \n",
    "    return all_objects\n",
    "\n",
    "def draw_objects(image_path, objects, output_path):\n",
    "    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def process_folder(input_folder, output_folder, max_tile_size=(2000, 2000)):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_out.bmp\")\n",
    "            \n",
    "            objects = process_image(input_path, max_tile_size)\n",
    "            draw_objects(input_path, objects, output_path)\n",
    "            print(f\"Processed: {filename} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2300.392] global loadsave.cpp:268 findDecoder imread_('sar_image.bmp'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Не удалось загрузить файл: sar_image.bmp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     69\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33msar_image.bmp\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Укажите путь к вашему .bmp файлу\u001b[39;00m\n\u001b[32m     70\u001b[39m output_path = \u001b[33m\"\u001b[39m\u001b[33msegmented_sar_image_with_boxes.bmp\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mprocess_and_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mprocess_and_visualize\u001b[39m\u001b[34m(image_path, output_path, n_clusters)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_and_visualize\u001b[39m(image_path, output_path, n_clusters=\u001b[32m3\u001b[39m):\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Обработка изображения и получение объектов\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     objects = \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# Рисование объектов на изображении\u001b[39;00m\n\u001b[32m     46\u001b[39m     draw_objects(image_path, objects, output_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mprocess_image\u001b[39m\u001b[34m(image_path, n_clusters)\u001b[39m\n\u001b[32m     11\u001b[39m sar_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sar_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mНе удалось загрузить файл: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 2. Предобработка\u001b[39;00m\n\u001b[32m     16\u001b[39m denoised_image = cv2.medianBlur(sar_image, \u001b[32m5\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Не удалось загрузить файл: sar_image.bmp"
     ]
    }
   ],
   "source": [
    "# Функция для рисования объектов (прямоугольников) на изображении\n",
    "def draw_objects(image_path, objects, output_path):\n",
    "    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "    for x1, y1, x2, y2 in objects:\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "# Функция для обработки изображения и извлечения объектов\n",
    "def process_image(image_path, n_clusters=3):\n",
    "    # 1. Загрузка данных\n",
    "    sar_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if sar_image is None:\n",
    "        raise ValueError(f\"Не удалось загрузить файл: {image_path}\")\n",
    "\n",
    "    # 2. Предобработка\n",
    "    denoised_image = cv2.medianBlur(sar_image, 5)\n",
    "    normalized_image = (denoised_image - np.min(denoised_image)) / (np.max(denoised_image) - np.min(denoised_image))\n",
    "\n",
    "    # 3. Кластеризация\n",
    "    pixels = normalized_image.reshape(-1, 1)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(pixels)\n",
    "    labels = kmeans.labels_.reshape(normalized_image.shape)\n",
    "\n",
    "    # 4. Постобработка и извлечение объектов\n",
    "    objects = []\n",
    "    for cluster_id in range(1, n_clusters):  # Пропускаем кластер 0 (фон)\n",
    "        binary_mask = (labels == cluster_id).astype(np.uint8)\n",
    "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))\n",
    "\n",
    "        # Находим контуры объектов\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 100:  # Фильтр по минимальной площади\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                objects.append((x, y, x + w, y + h))\n",
    "\n",
    "    return objects\n",
    "\n",
    "# Основная функция для обработки одного файла\n",
    "def process_and_visualize(image_path, output_path, n_clusters=3):\n",
    "    # Обработка изображения и получение объектов\n",
    "    objects = process_image(image_path, n_clusters=n_clusters)\n",
    "    \n",
    "    # Рисование объектов на изображении\n",
    "    draw_objects(image_path, objects, output_path)\n",
    "    print(f\"Processed: {image_path} -> {output_path}\")\n",
    "\n",
    "    # Визуализация (опционально)\n",
    "    sar_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    segmented_image = cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Исходное изображение\")\n",
    "    plt.imshow(sar_image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Сегментация с объектами\")\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(output_path), cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"sar_image.bmp\"  # Укажите путь к вашему .bmp файлу\n",
    "    output_path = \"segmented_sar_image_with_boxes.bmp\"\n",
    "    process_and_visualize(image_path, output_path, n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронка попробовал DeepLabV3+ она нам не подходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8.jpg: 3 objects -> output/8_out.jpg\n",
      "Processed 9.jpg: 1 objects -> output/9_out.jpg\n",
      "Processed 4.jpg: 17 objects -> output/4_out.jpg\n",
      "Processed 5.jpg: 10 objects -> output/5_out.jpg\n",
      "Processed 7.jpg: 14 objects -> output/7_out.jpg\n",
      "Processed 6.jpg: 11 objects -> output/6_out.jpg\n",
      "Processed 2.jpg: 13 objects -> output/2_out.jpg\n",
      "Processed 3.jpg: 4 objects -> output/3_out.jpg\n",
      "Processed 1.jpg: 15 objects -> output/1_out.jpg\n",
      "CSV summary saved to output/summary.csv\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"images\"\n",
    "output_folder = \"output\"\n",
    "process_folder(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
