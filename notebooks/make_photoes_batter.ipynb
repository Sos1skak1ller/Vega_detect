{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8736097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Авто-установка OpenCV при необходимости\n",
    "import importlib, sys, subprocess\n",
    "\n",
    "try:\n",
    "    importlib.import_module(\"cv2\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Installing opencv-python-headless...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"opencv-python-headless\"])\n",
    "    importlib.invalidate_caches()\n",
    "    import cv2  # noqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df262f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f22d890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено изображений: 9\n",
      "Форматы: {'.jpg'}\n",
      "Примеры: ['1.jpg', '2.jpg', '3.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Конфигурация путей и параметров (только улучшение качества)\n",
    "IMAGES_DIR = \"/Users/sosiska_killer/Documents/diplom/research_algorithm/Vega_detect/images\"\n",
    "OUTPUT_DIR = \"/Users/sosiska_killer/Documents/diplom/research_algorithm/Vega_detect/output/auto_enhanced\"\n",
    "INTER_DIR = os.path.join(OUTPUT_DIR, \"intermediate\")\n",
    "ENH_DIR = os.path.join(OUTPUT_DIR, \"enhanced\")\n",
    "for d in [OUTPUT_DIR, INTER_DIR, ENH_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Параметры фильтрации/улучшения\n",
    "WINDOW_SIZE = 7            # размер окна для Lee\n",
    "LEE_DAMPING_K = 1.0        # коэффициент подавления шума (0.5-2.0)\n",
    "\n",
    "# Параметры контраста (затемнение темных + осветление светлых)\n",
    "GAMMA_DARK = 0.7           # затемнение темных участков (0.5-1.0, меньше = темнее)\n",
    "GAMMA_LIGHT = 1.3          # осветление светлых участков (1.0-2.0, больше = светлее)\n",
    "THRESHOLD = 0.5            # порог разделения темных/светлых (0-1)\n",
    "\n",
    "# Список входных файлов (все форматы изображений)\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif', '*.gif', '*.webp', '*.tga', '*.dds', '*.exr', '*.hdr', '*.ppm', '*.pgm', '*.pbm']\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(os.path.join(IMAGES_DIR, ext)))\n",
    "    image_paths.extend(glob.glob(os.path.join(IMAGES_DIR, ext.upper())))  # заглавные расширения\n",
    "\n",
    "image_paths = sorted(list(set(image_paths)))  # убираем дубликаты и сортируем\n",
    "print(f\"Найдено изображений: {len(image_paths)}\")\n",
    "if image_paths:\n",
    "    print(f\"Форматы: {set([os.path.splitext(p)[1].lower() for p in image_paths])}\")\n",
    "    print(f\"Примеры: {[os.path.basename(p) for p in image_paths[:3]]}\")\n",
    "else:\n",
    "    print(\"Изображения не найдены!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b6d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции: нормализация и Lee-фильтр\n",
    "\n",
    "def normalize_to_uint8(img: np.ndarray) -> np.ndarray:\n",
    "    if img.dtype != np.float32 and img.dtype != np.float64:\n",
    "        img = img.astype(np.float32)\n",
    "    mn, mx = np.min(img), np.max(img)\n",
    "    if mx - mn < 1e-9:\n",
    "        return np.zeros_like(img, dtype=np.uint8)\n",
    "    out = (img - mn) / (mx - mn)\n",
    "    out = (out * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def lee_filter(image: np.ndarray, window_size: int = 7, k: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Классический Lee-фильтр (интенсивность).\n",
    "    image: ожидается uint8 или float32, 1 канал.\n",
    "    window_size: нечетное число.\n",
    "    k: коэффициент подавления шума (0.5..2.0)\n",
    "    \"\"\"\n",
    "    if image.ndim == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if image.dtype != np.float32:\n",
    "        img = image.astype(np.float32)\n",
    "    else:\n",
    "        img = image\n",
    "\n",
    "    half = window_size // 2\n",
    "    # Скользящие среднее и дисперсия через боковой фильтр\n",
    "    mean = cv2.boxFilter(img, ddepth=-1, ksize=(window_size, window_size), normalize=True, borderType=cv2.BORDER_REFLECT)\n",
    "    mean_sq = cv2.boxFilter(img * img, ddepth=-1, ksize=(window_size, window_size), normalize=True, borderType=cv2.BORDER_REFLECT)\n",
    "    var = (mean_sq - mean * mean).clip(0)\n",
    "\n",
    "    # Оценка дисперсии шума: медиана по var\n",
    "    noise_var = np.median(var)\n",
    "    # Вес по Ли\n",
    "    w = var / (var + k * noise_var + 1e-12)\n",
    "    out = mean + w * (img - mean)\n",
    "    return out.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ebc721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции: улучшение контраста (затемнение темных + осветление светлых)\n",
    "\n",
    "def enhance_contrast_dark_light(img_f32: np.ndarray,\n",
    "                                gamma_dark: float = 0.7,      # затемнение темных (0.5-1.0)\n",
    "                                gamma_light: float = 1.3,     # осветление светлых (1.0-2.0)\n",
    "                                threshold: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"Улучшение контраста: затемняет темные участки и осветляет светлые.\n",
    "    threshold: порог разделения темных/светлых участков (0-1)\n",
    "    \"\"\"\n",
    "    # Нормализуем к [0,1]\n",
    "    img_norm = normalize_to_uint8(img_f32).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Создаем маски для темных и светлых участков\n",
    "    dark_mask = img_norm < threshold\n",
    "    light_mask = img_norm >= threshold\n",
    "    \n",
    "    # Применяем гамма-коррекцию отдельно к темным и светлым участкам\n",
    "    result = img_norm.copy()\n",
    "    \n",
    "    # Затемняем темные участки\n",
    "    if np.any(dark_mask):\n",
    "        result[dark_mask] = np.power(img_norm[dark_mask], gamma_dark)\n",
    "    \n",
    "    # Осветляем светлые участки  \n",
    "    if np.any(light_mask):\n",
    "        result[light_mask] = np.power(img_norm[light_mask], gamma_light)\n",
    "    \n",
    "    # Возвращаем к uint8\n",
    "    return (result * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17bb86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции: детекция малых объектов vs шум\n",
    "\n",
    "def detect_small_objects(img_u8: np.ndarray,\n",
    "                         min_area: int = 8,\n",
    "                         max_area: int = 400,\n",
    "                         morph_open: int = 3,\n",
    "                         morph_close: int = 5) -> Tuple[np.ndarray, List[Tuple[int,int,int,int]]]:\n",
    "    \"\"\"Возвращает бинарную маску объектов и bounding-box'ы найденных малых объектов.\n",
    "    Шум подавляется морфологией и порогом площади.\n",
    "    \"\"\"\n",
    "    # Адаптивный порог (Otsu + небольшое усиление)\n",
    "    _, th = cv2.threshold(img_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Немного ужесточим порог (повышаем пороговую границу на 10%)\n",
    "    hist_thr = int(max(0, min(255, 1.1 * _)))\n",
    "    _, th2 = cv2.threshold(img_u8, hist_thr, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Морфологическая фильтрация\n",
    "    if morph_open > 0:\n",
    "        k1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_open, morph_open))\n",
    "        th2 = cv2.morphologyEx(th2, cv2.MORPH_OPEN, k1)\n",
    "    if morph_close > 0:\n",
    "        k2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_close, morph_close))\n",
    "        th2 = cv2.morphologyEx(th2, cv2.MORPH_CLOSE, k2)\n",
    "\n",
    "    # Поиск контуров и фильтрация по площади\n",
    "    cnts, _h = cv2.findContours(th2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros_like(th2)\n",
    "    boxes: List[Tuple[int,int,int,int]] = []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area:\n",
    "            # шум\n",
    "            continue\n",
    "        if area <= max_area:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            boxes.append((x,y,w,h))\n",
    "            cv2.drawContours(mask, [c], -1, 255, thickness=-1)\n",
    "        else:\n",
    "            # более крупные объекты можно игнорировать или тоже отмечать\n",
    "            pass\n",
    "    return mask, boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b76ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываем 1/9: 1.jpg\n",
      "Обрабатываем 2/9: 2.jpg\n",
      "Обрабатываем 3/9: 3.jpg\n",
      "Обрабатываем 4/9: 4.jpg\n",
      "Обрабатываем 5/9: 5.jpg\n",
      "Обрабатываем 6/9: 6.jpg\n",
      "Обрабатываем 7/9: 7.jpg\n",
      "Обрабатываем 8/9: 8.jpg\n",
      "Обрабатываем 9/9: 9.jpg\n",
      "Готово. Успешно обработано файлов: 9 из 9\n"
     ]
    }
   ],
   "source": [
    "# Пакетная обработка изображений: только улучшение качества\n",
    "\n",
    "processed_count = 0\n",
    "for idx, img_path in enumerate(image_paths, start=1):\n",
    "    base = os.path.basename(img_path)\n",
    "    name, ext = os.path.splitext(base)\n",
    "    \n",
    "    # Читаем изображение (поддерживает все форматы)\n",
    "    img_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        print(f\"[WARN] Не удалось прочитать {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Обрабатываем {idx}/{len(image_paths)}: {base}\")\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 1) Подавление спекл-шума (Lee)\n",
    "    lee = lee_filter(gray, window_size=WINDOW_SIZE, k=LEE_DAMPING_K)\n",
    "\n",
    "    # 2) Улучшение контраста (затемнение темных + осветление светлых)\n",
    "    enhanced_u8 = enhance_contrast_dark_light(lee, gamma_dark=GAMMA_DARK, gamma_light=GAMMA_LIGHT, threshold=THRESHOLD)\n",
    "\n",
    "    # 3) Сохранение в том же формате что и исходный файл\n",
    "    inter_path = os.path.join(INTER_DIR, f\"{name}_lee{ext}\")\n",
    "    enh_path = os.path.join(ENH_DIR, f\"{name}_enhanced{ext}\")\n",
    "    \n",
    "    # Определяем параметры сжатия в зависимости от формата\n",
    "    if ext.lower() in ['.jpg', '.jpeg']:\n",
    "        cv2.imwrite(inter_path, normalize_to_uint8(lee), [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "        cv2.imwrite(enh_path, enhanced_u8, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "    elif ext.lower() in ['.png']:\n",
    "        cv2.imwrite(inter_path, normalize_to_uint8(lee), [cv2.IMWRITE_PNG_COMPRESSION, 3])\n",
    "        cv2.imwrite(enh_path, enhanced_u8, [cv2.IMWRITE_PNG_COMPRESSION, 3])\n",
    "    else:\n",
    "        # Для остальных форматов без дополнительных параметров\n",
    "        cv2.imwrite(inter_path, normalize_to_uint8(lee))\n",
    "        cv2.imwrite(enh_path, enhanced_u8)\n",
    "    \n",
    "    processed_count += 1\n",
    "\n",
    "print(f\"Готово. Успешно обработано файлов: {processed_count} из {len(image_paths)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
